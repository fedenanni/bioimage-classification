{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af21fe6d",
   "metadata": {},
   "source": [
    "# Training a classifier on MNIST\n",
    "\n",
    "## First step: we load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9034f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4f50fb",
   "metadata": {},
   "source": [
    "## Let's check the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bc1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train: ' + str(train_X.shape))\n",
    "print('Y_train: ' + str(train_y.shape))\n",
    "print('X_test:  '  + str(test_X.shape))\n",
    "print('Y_test:  '  + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d8899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "for i in range(9):  \n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(train_X[i], cmap=pyplot.get_cmap('gray'))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dbab29",
   "metadata": {},
   "source": [
    "## Sub-sample the dataset for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ceb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SUBSAMPLE for speed ---\n",
    "n_train = 2000\n",
    "n_test = 500\n",
    "\n",
    "train_X = train_X[:n_train]\n",
    "train_y = train_y[:n_train]\n",
    "test_X = test_X[:n_test]\n",
    "test_y = test_y[:n_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3233ec2d",
   "metadata": {},
   "source": [
    "## How do we present images to a classifier?\n",
    "\n",
    "We explore two options:\n",
    "1. raw pixels\n",
    "2. image embeddings from ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6315a9",
   "metadata": {},
   "source": [
    "### Raw Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ae21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Flatten 28x28 grayscale images into 1D vectors ---\n",
    "# Each image (28x28) → vector of 784 features\n",
    "train_X_flat = train_X.reshape(n_train, -1)\n",
    "test_X_flat = test_X.reshape(n_test, -1)\n",
    "\n",
    "# --- Normalize pixel values (important for distance-based classifiers) ---\n",
    "train_pixels = train_X_flat / 255.0\n",
    "test_pixels = test_X_flat / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a72395",
   "metadata": {},
   "source": [
    "### Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd85ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Convert grayscale 28x28 → RGB 224x224x3\n",
    "train_X_rgb = np.repeat(train_X[..., np.newaxis], 3, -1)\n",
    "test_X_rgb = np.repeat(test_X[..., np.newaxis], 3, -1)\n",
    "train_X_resized = tf.image.resize(train_X_rgb, (224, 224)).numpy()\n",
    "test_X_resized = tf.image.resize(test_X_rgb, (224, 224)).numpy()\n",
    "\n",
    "# Preprocess for ResNet\n",
    "train_X_resized = preprocess_input(train_X_resized)\n",
    "test_X_resized = preprocess_input(test_X_resized)\n",
    "\n",
    "# Load pretrained ResNet (without top classifier)\n",
    "resnet = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "# Extract embeddings\n",
    "train_embeddings = resnet.predict(train_X_resized, verbose=1)\n",
    "test_embeddings = resnet.predict(test_X_resized, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed04814",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbour Classifier \n",
    "\n",
    "You can change the feature (pixels or embeddings and see the change in performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "knn.fit(train_embeddings, train_y) # or train_pixels for pixel-based KNN\n",
    "\n",
    "y_pred = knn.predict(test_embeddings) # or test_pixels for pixel-based KNN\n",
    "acc = accuracy_score(test_y, y_pred)\n",
    "print(f\"KNN on pretrained ResNet embeddings (n_train={n_train}, n_test={n_test}): {acc:.4f}\")\n",
    "\n",
    "# Precision, Recall, F1 report\n",
    "report = classification_report(test_y, y_pred, digits=3)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_y, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(10))\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(f\"Confusion Matrix – KNN on ResNet Embeddings ({n_train} train, {n_test} test)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0cb724",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef0b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM classifier\n",
    "svm = SVC() \n",
    "svm.fit(train_embeddings, train_y) # or train_pixels for pixel-based SVM\n",
    "\n",
    "y_pred = svm.predict(test_embeddings) # or test_pixels for pixel-based SVM\n",
    "acc = accuracy_score(test_y, y_pred)\n",
    "print(f\"SVM on pretrained ResNet embeddings (n_train={n_train}, n_test={n_test}): {acc:.4f}\")\n",
    "\n",
    "# Precision, Recall, F1 report\n",
    "report = classification_report(test_y, y_pred, digits=3)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_y, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(10))\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(f\"Confusion Matrix – KNN on ResNet Embeddings ({n_train} train, {n_test} test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52933c11",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e77f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert labels to one-hot\n",
    "train_y_cat = to_categorical(train_y, 10)\n",
    "test_y_cat = to_categorical(test_y, 10)\n",
    "\n",
    "# Define a simple MLP\n",
    "mlp = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(train_embeddings.shape[1],)), # or train_pixels.shape[1] for pixel-based MLP\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile\n",
    "mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = mlp.fit(train_embeddings, train_y_cat, # or train_pixels for pixel-based MLP\n",
    "                  validation_split=0.1,\n",
    "                  epochs=10,\n",
    "                  batch_size=64,\n",
    "                  verbose='no')\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = mlp.evaluate(test_embeddings, test_y_cat) # or test_pixels for pixel-based MLP\n",
    "print(f\"MLP on pretrained ResNet embeddings (n_train={n_train}, n_test={n_test}): {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "# Predictions\n",
    "y_pred = mlp.predict(test_embeddings).argmax(axis=1) # or test_pixels for pixel-based MLP\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_y, y_pred, digits=3))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_y, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(10))\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(\"Confusion Matrix – MLP on ResNet Embeddings\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioimage-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
